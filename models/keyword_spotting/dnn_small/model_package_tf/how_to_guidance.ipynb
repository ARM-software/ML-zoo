{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) 2023 Arm Limited or its affiliates. All rights reserved.\n",
    "#\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the License); you may\n",
    "# not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an AS IS BASIS, WITHOUT\n",
    "# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN_Small - Optimised\n",
    "\n",
    "Here we reproduce the models with our established codebase and ModelPackage approach for your convenience.\n",
    "\n",
    "## Model-Package Overview:\n",
    "\n",
    "| Model           \t| DNN_Small                            \t|\n",
    "|:---------------:\t|:---------------------------------------------------------------:\t|\n",
    "| <u>**Format**</u>:          \t| Keras, Saved Model, TensorFlow Lite int8, TensorFlow Lite fp32 |\n",
    "| <u>**Feature**</u>:         \t| Keyword spotting for Arm Cortex-M CPUs |\n",
    "| <u>**Architectural Delta w.r.t. Vanilla**</u>: | None |\n",
    "| <u>**Domain**</u>:         \t| Keyword spotting |\n",
    "| <u>**Package Quality**</u>: \t| Optimised |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents <a name=\"index_page\"></a>\n",
    "\n",
    "This how-to guidance presents the key steps to reproduce everything in this package. The contents are organised as below. We provided the internal navigation links for users to easy-jump among different sections.  \n",
    "\n",
    "    \n",
    "* [1.0 Model recreation](#model_recreation)\n",
    "\n",
    "* [2.0 Training](#training)\n",
    "\n",
    "* [3.0 Testing](#testing)\n",
    "\n",
    "* [4.0 Optimization](#optimization)\n",
    "\n",
    "* [5.0 Quantization and TFLite conversion](#tflite_conversion)\n",
    "\n",
    "* [6.0 Inference the TFLite model files](#tflite_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Model Recreation<a name=\"model_recreation\"></a>\n",
    "\n",
    "In order to recreate the model you will first need to be using ```Python3.7``` and install the requirements in ```requirements.txt```.\n",
    "\n",
    "Once you have these requirements satisfied you can execute the recreation script contained within this folder, just run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-31 13:25:23.242199: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Untarring speech_commands_v0.02.tar.gz...\n",
      "2023-01-31 13:26:16.311986: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2023-01-31 13:26:16.348776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2023-01-31 13:26:16.348818: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-31 13:26:16.369436: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-01-31 13:26:16.369509: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-01-31 13:26:16.372294: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-31 13:26:16.372684: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-31 13:26:16.373267: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-01-31 13:26:16.374012: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-01-31 13:26:16.374168: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-01-31 13:26:16.374680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-01-31 13:26:16.374967: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-31 13:26:16.375884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2023-01-31 13:26:16.376614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-01-31 13:26:16.376682: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-31 13:26:16.822126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-01-31 13:26:16.822161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2023-01-31 13:26:16.822173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2023-01-31 13:26:16.822780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10939 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2023-01-31 13:26:17.956358: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2023-01-31 13:26:18.216079: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-01-31 13:26:18.216285: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2023-01-31 13:26:18.216661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2023-01-31 13:26:18.216906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-01-31 13:26:18.216936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-01-31 13:26:18.216946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2023-01-31 13:26:18.216953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2023-01-31 13:26:18.217236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10939 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)\n",
      "2023-01-31 13:26:18.235442: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3492140000 Hz\n",
      "2023-01-31 13:26:18.236450: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.011ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n",
      "2023-01-31 13:26:18.268723: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:345] Ignored output_format.\n",
      "2023-01-31 13:26:18.268758: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:348] Ignored drop_control_dependency.\n",
      "2023-01-31 13:26:18.271003: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-01-31 13:26:18.272912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2023-01-31 13:26:18.273329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-01-31 13:26:18.273362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-01-31 13:26:18.273373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2023-01-31 13:26:18.273385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2023-01-31 13:26:18.273700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10939 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)\n",
      "Converted model saved to dnn.tflite.\n",
      "Running TFLite evaluation on validation set...\n",
      "2023-01-31 13:26:18.314546: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "[[371   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 238  16   9   5  30  11  10  15   7   9  21]\n",
      " [  0   7 341   8   0   6  26   5   1   0   0   3]\n",
      " [  0   8   7 316   5  17   0   5   2   1   4  41]\n",
      " [  0   8   1   2 287   3   5   4   6  19   7   8]\n",
      " [  0  10   1  22   2 317   2   0   5   2   1  15]\n",
      " [  0   5  27   2   1   2 299   9   0   3   0   4]\n",
      " [  1  13   2   2   0   2   3 334   2   2   0   2]\n",
      " [  2   9   1   1   6   6   2   0 318  13   1   4]\n",
      " [  1   4   1   0  29   0   1   1  17 311   4   4]\n",
      " [  2   2   0   1  15   5   0   1   4   5 310   5]\n",
      " [  0  10   1  38   8  26   2   1   3   1   1 281]]\n",
      "Validation accuracy = 83.76%(N=4445)\n",
      "Running TFLite evaluation on test set...\n",
      "[[408   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 274  12  20   8  11  16  13  20   7   8  19]\n",
      " [  1   9 375   3   0   6  20   0   0   0   1   4]\n",
      " [  0  14   5 312   1  33   6   0   0   0   3  31]\n",
      " [  0  12   0   3 362   5   3   5   8  11  13   3]\n",
      " [  0  10   2  34   2 332   5   0   5   0   3  13]\n",
      " [  0  12  27   5   4   1 339  17   1   2   2   2]\n",
      " [  0  12   0   2   4   1   9 362   1   3   0   2]\n",
      " [  1  12   0   3   3  14   1   1 336  20   1   4]\n",
      " [  1   6   3   2  16   0   3   1  19 338   2  11]\n",
      " [  0   5   1   2  22   4   3   0   0   2 367   5]\n",
      " [  0  17   0  65   6  17   3   2   2   5   2 283]]\n",
      "Test accuracy = 83.60%(N=4890)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-31 13:26:30.279559: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Untarring speech_commands_v0.02.tar.gz...\n",
      "2023-01-31 13:27:20.964068: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2023-01-31 13:27:21.007726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2023-01-31 13:27:21.007765: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-31 13:27:21.028042: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-01-31 13:27:21.028131: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-01-31 13:27:21.030956: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-31 13:27:21.031218: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-31 13:27:21.031788: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-01-31 13:27:21.032512: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-01-31 13:27:21.032668: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-01-31 13:27:21.033033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-01-31 13:27:21.033325: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-31 13:27:21.034039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2023-01-31 13:27:21.034415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-01-31 13:27:21.034486: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-31 13:27:21.478837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-01-31 13:27:21.478873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2023-01-31 13:27:21.478882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2023-01-31 13:27:21.479411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10939 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2023-01-31 13:27:22.568489: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2023-01-31 13:27:22.830822: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-01-31 13:27:22.831041: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2023-01-31 13:27:22.831444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2023-01-31 13:27:22.831775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-01-31 13:27:22.831807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-01-31 13:27:22.831816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2023-01-31 13:27:22.831823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2023-01-31 13:27:22.832109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10939 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)\n",
      "2023-01-31 13:27:22.851539: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3492140000 Hz\n",
      "2023-01-31 13:27:22.852738: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.013ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n",
      "2023-01-31 13:27:22.888443: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:345] Ignored output_format.\n",
      "2023-01-31 13:27:22.888491: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:348] Ignored drop_control_dependency.\n",
      "2023-01-31 13:27:22.891172: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-01-31 13:27:22.893139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2023-01-31 13:27:22.893390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-01-31 13:27:22.893420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-01-31 13:27:22.893430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2023-01-31 13:27:22.893437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2023-01-31 13:27:22.893709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10939 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)\n",
      "2023-01-31 13:27:22.923079: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 9, output_inference_type: 9\n",
      "Quantized model saved to dnn_quantized.tflite.\n",
      "Running TFLite evaluation on validation set...\n",
      "[[371   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 241  17  14   5  27  12   9  17   6   7  16]\n",
      " [  0  11 340  11   4   5  21   4   1   0   0   0]\n",
      " [  0  15   7 315  10  14   1   2   2   1   6  33]\n",
      " [  0  10   1   6 282   4   6   3   5  19  10   4]\n",
      " [  0  17   2  26   8 300   1   0   6   0   4  13]\n",
      " [  0   8  30   3   6   1 293   7   0   1   2   1]\n",
      " [  0  17   2   4   6   1   9 316   1   2   4   1]\n",
      " [  2   9   1   1  10   4   2   2 317  11   0   4]\n",
      " [  1   8   1   2  33   0   0   2  15 303   6   2]\n",
      " [  2   6   0   2  25   5   0   0   2   1 304   3]\n",
      " [  0  16   1  47  15  27   2   1   3   1   4 255]]\n",
      "Validation accuracy = 81.82%(N=4445)\n",
      "Running TFLite evaluation on test set...\n",
      "[[408   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 281  13  23  11  10  14  14  21   6   6   9]\n",
      " [  0  12 372   6   6   6  13   0   0   0   1   3]\n",
      " [  0  19   8 311   6  28   4   0   0   0   4  25]\n",
      " [  0  20   2   6 359   6   1   2   6   7  14   2]\n",
      " [  0  15   5  36  10 318   3   0   4   2   2  11]\n",
      " [  0  12  33   6  13   3 320  19   0   2   2   2]\n",
      " [  1  17   0   4   5   1  11 347   1   1   7   1]\n",
      " [  0  16   0   6   8  16   1   1 326  18   3   1]\n",
      " [  1   6   3   4  37   1   3   2  19 314   3   9]\n",
      " [  0  10   0   6  28   3   4   0   0   1 354   5]\n",
      " [  0  19   0  73  18  19   3   2   3   4   2 259]]\n",
      "Test accuracy = 81.17%(N=4890)\n"
     ]
    }
   ],
   "source": [
    "!bash ./recreate_model.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this script will use the pre-trained checkpoint files supplied in the ```./model_archive/model_source/weights``` folder to generate the TFLite files and perform evaluation on the test set. Both an fp32 version and a quantized version will be produced. The quantized version will use post-training quantization to fully quantize it.\n",
    "\n",
    "If you want to run training from scratch you can do this by supplying ```--train``` when running the script. For example:\n",
    "\n",
    "```bash\n",
    "bash ./recreate_model.sh --train\n",
    "```\n",
    "\n",
    "Training is then performed and should produce a model to the stated accuracy in this repository. Note that exporting to TFLite will still happen with the baseline pre-trained checkpoint files, so you will need to re-run the script and this time supply the path to the new checkpoint files you want to use, for example:\n",
    "\n",
    "```bash\n",
    "bash ./recreate_model.sh --ckpt <checkpoint_path>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Training<a name=\"training\"></a>\n",
    "\n",
    "The training scripts can be used to recreate any of the models from the [Hello Edge paper](https://arxiv.org/pdf/1711.07128.pdf) provided the right hyperparameters are used. The training commands with all the hyperparameters to reproduce the model in this repository are given [here](recreate_model.sh). The model in this part of the repository represents just one variation of the models from the paper, other varieties are covered in other parts of the repository.\n",
    "\n",
    "\n",
    "As a general example of how to train a DNN with 3 fully-connected layers with 128 neurons in each layer, run:\n",
    "```\n",
    "python train.py --model_architecture dnn --model_size_info 128 128 128\n",
    "```\n",
    "\n",
    "The command line argument *--model_size_info* is used to pass the neural network layer\n",
    "dimensions such as number of layers, convolution filter size/stride as a list to models.py,\n",
    "which builds the TensorFlow graph based on the provided model architecture\n",
    "and layer dimensions. For more info on *model_size_info* for each network architecture see\n",
    "[models.py](model_core_utils/models.py).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Testing<a name=\"testing\"></a>\n",
    "To run inference on the trained model from a checkpoint and get accuracy on validation and test sets, run:\n",
    "```\n",
    "python evaluation.py --model_architecture dnn --model_size_info 128 128 128 --checkpoint <checkpoint_path>\n",
    "```\n",
    "**The model and feature extraction parameters passed to this script should match those used in the Training step.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Optimization<a name=\"optimization\"></a>\n",
    "\n",
    "We introduce an *optional* step to optimize the trained keyword spotting model for deployment.\n",
    "\n",
    "Here we use TensorFlow's [weight clustering API](https://www.tensorflow.org/model_optimization/guide/clustering) to reduce the compressed model size and optimize inference on supported hardware. 32 weight clusters and kmeans++ cluster intialization method are used as the clustering hyperparameters.\n",
    "\n",
    "To optimize your trained model (e.g. a DNN), a trained model checkpoint is needed to run clustering and fine-tuning on.\n",
    "You can use the pre-trained checkpoints provided, or train your own model and use the resulting checkpoint.\n",
    "\n",
    "To apply the optimization and fine-tuning, run the following command:\n",
    "```\n",
    "python optimisations.py --model_architecture dnn --model_size_info 128 128 128 --checkpoint <checkpoint_path>\n",
    "```\n",
    "**The model and feature extraction parameters used here should match those used in the Training step, except for the number of training steps.\n",
    "The number of training steps is reduced since the optimization step only requires fine-tuning.**\n",
    "\n",
    "This will generate a clustered model checkpoint that can be used in the quantization step to generate a quantized and clustered TFLite model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Quantization and TFLite Conversion<a name=\"tflite_conversion\"></a>\n",
    "\n",
    "You can now use TensorFlow's\n",
    "[post training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization) to\n",
    "make quantization of the trained models super simple.\n",
    "\n",
    "To quantize your trained model (e.g. a DNN) run:\n",
    "```\n",
    "python convert_to_tflite.py --model_architecture dnn --model_size_info 128 128 128 --checkpoint <checkpoint_path> [--inference_type int8|int16]\n",
    "```\n",
    "**The model and feature extraction parameters used here should match those used in the Training step.**\n",
    "\n",
    "The ```inference_type``` parameter is *optional* and to be used if a fully quantized model with inputs and outputs of type int8 or int16 is needed. It defaults to fp32.\n",
    "\n",
    "In this example, this step will produce a quantized TFLite file *dnn_quantized.tflite*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test the accuracy of this quantized model on the test set by running:\n",
    "```\n",
    "python evaluation.py --tflite_path dnn_quantized.tflite\n",
    "```\n",
    "**The model and feature extraction parameters used here should match those used in the Training step.**\n",
    "\n",
    "`convert_to_tflite.py` uses post-training quantization to generate a quantized model by default. If you wish to convert to a floating point TFLite model, use the command below:\n",
    "\n",
    "```\n",
    "python convert_to_tflite.py --model_architecture dnn --model_size_info 128 128 128 --checkpoint <checkpoint_path> --no-quantize\n",
    "```\n",
    "\n",
    "This will produce a floating point TFLite file *dnn.tflite*. You can test the accuracy of this floating point model using `evaluation.py` as above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Single inference of the TFLite model files <a name=\"tflite_inference\"></a>\n",
    "\n",
    "You can conduct TFLite inference for .fp32 and .int8 model files by using the following command: \n",
    "\n",
    "```python dnn_s_inference_tflite.py --labels validation_utils/labels.txt --wav <path_to_wav_file> --tflite_path <path_to_tflite_file>```\n",
    "\n",
    "**The feature extraction parameters used here should match those used in the Training step.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
